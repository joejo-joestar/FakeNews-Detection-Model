{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📰 Fake News Detection Using Ensemble Learning\n",
    "\n",
    "---\n",
    "\n",
    "| S. No |    ID No.     | Name             |\n",
    "| ----: | :-----------: | :--------------- |\n",
    "|    1. | 2022A7PS0003U | Yusra Hakim      |\n",
    "|    2. | 2022A7PS0019U | Joseph Cijo      |\n",
    "|    3. | 2022A7PS0031U | Ritvik Bhatnagar |\n",
    "\n",
    "This Jupyter Notebook is for the project in Data Mining (CS F415) course. It contains the code used for preparing the ensemble model using the [dataset](#dataset-used) mentioned below.\n",
    "\n",
    "### Dataset Details\n",
    "\n",
    "**Dataset introduced in:**\n",
    "V. Pawan Kumar, A. Prateek, A. Ivone and P. Radu, \"WELFake: Word Embedding Over Linguistic Features for Fake News Detection,\" _IEEE Transactions on Computational Social Systems_, vol. 8, no. 4, pp. 881-893, 2021.\n",
    "[Kaggle | WELFake Dataset](https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification)\n",
    "\n",
    "### Setting Up an Environment for the Jupyter notebook\n",
    "\n",
    "Firstly install Miniconda from [here](https://docs.anaconda.com/miniconda/install/).\n",
    "\n",
    "Then open a command prompt in this directory, and run the following. This will create and activate an environment called \"PROJ\".\n",
    "\n",
    "```bash\n",
    "    conda create -n proj python=3.12\n",
    "    conda activate proj\n",
    "```\n",
    "\n",
    "After running this, your CMD prompt should have a \"`(proj)`\" prefixed at the start.\n",
    "\n",
    "Run the following command to install packages, such as [PyTorch](https://pytorch.org/get-started/locally/). This will take some time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%pip uninstall torch -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%conda install -n proj ipykernel ipywidgets --update-deps --force-reinstall\n",
    "%conda install -n proj nltk\n",
    "%conda install -n proj conda-forge::textblob\n",
    "%pip install scikit-learn matplotlib seaborn pandas pyperclip contractions scipy numpy\n",
    "%conda install -n proj conda-forge::transformers\n",
    "%conda install -n proj conda-forge::lightgbm\n",
    "%pip install torch --index-url https://download.pytorch.org/whl/cu128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to select the PROJ environment at the bottom-right.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 📚 Outline\n",
    "\n",
    "To train the model, the following steps must be followed:\n",
    "\n",
    "<img src=\"assets/archdiag.png\" size=64/>\n",
    "\n",
    "The model will accept two inputs:\n",
    "1. The headline of the article\n",
    "2. Content of the article (Optional)\n",
    "\n",
    "And give an output if it is fake news or factual (real) news.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "# from transformers.models.distilbert import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "import contractions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 📑 Dataset Tomfoolery\n",
    "\n",
    "The dataset is a CSV file with the following columns:\n",
    "\n",
    "- _title_: the title of the article\n",
    "- _text_: the text of the article\n",
    "- _label_: the label of the article (0 for fake, 1 for real)\n",
    "\n",
    "The dataset used is the WELFake dataset [available here](https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification)\n",
    "\n",
    "This dataset is a collection of news articles, with each article labeled as either fake or real. The dataset contains 10,000 articles, with 5,000 fake and 5,000 real articles. The articles are in English and cover a wide range of topics, including politics, sports, entertainment, and technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_and_corpora/WELFake_Dataset.csv\", index_col=0)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✂️ Splitting Dataset\n",
    "\n",
    "The dataset is split as\n",
    "-  80% → Training + Validation Set\n",
    "-  20% → Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set size: {train_df.shape}\")\n",
    "train_df.to_csv(\"dataset_and_corpora/train.csv\", index=False)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTesting set size: {test_df.shape}\")\n",
    "test_df.to_csv(\"dataset_and_corpora/test.csv\", index=False)\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👾 Data Preprocessing\n",
    "\n",
    "The data is preprocessed using the following steps\n",
    "1. [Text Cleaning](#text-cleaning)\n",
    "   1. [Lowercasing & URL Removal](#lowercasing-url-removal)\n",
    "   2. [Contractions Expansion](#contractions-expansion)\n",
    "   3. [Tokenization](#tokenization)\n",
    "   4. [Lemmatization](#lemmatization)\n",
    "   5. [Stopword Removal](#stopword-removal)\n",
    "2. [Data Augmentaiton](#data-augmentation)\n",
    "   1. [Synonym Replacement](#synonym-replacement)\n",
    "   2. [Random Insertion](#random-insertion)\n",
    "   3. [Random Swap](#random-swap)\n",
    "   4. [Random Deletion](#random-deletion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧹 Data Cleaning\n",
    "\n",
    "The text in the datast has to be cleaned before it can be used for training the model. The following steps are used for cleaning the text.\n",
    "\n",
    "[Kaggle | Getting started with Text Preprocessing](https://www.kaggle.com/code/sudalairajkumar/getting-started-with-text-preprocessing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Text Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_title_and_text(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge the 'title' and 'text' fields into a single 'content' field.\n",
    "\n",
    "    :param df: Input DataFrame\n",
    "    :return: DataFrame with a new 'content' field\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"content\"] = df[\"title\"].fillna(\"\") + \" \" + df[\"text\"].fillna(\"\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handle missing data in the DataFrame by removing rows with any empty, NaN values, or rows containing only whitespaces.\n",
    "\n",
    "    :param df: DataFrame to process\n",
    "    :return: DataFrame with rows containing any empty, NaN values, or whitespaces-only content removed\n",
    "    \"\"\"\n",
    "\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "    df = df.replace(\"\", np.nan)\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercasing & URL Removal\n",
    "\n",
    "The text is converted to lowercase and URLs are removed from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_and_remove_urls(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert text to lowercase and remove URLs.\n",
    "\n",
    "    :param text: Input text\n",
    "    :return: Processed text with URLs removed\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contractions Expansion\n",
    "\n",
    "Contractions are expanded to their full form. For example, \"I'm\" is expanded to \"I am\". Using the [`contractions`](https://github.com/kootenpv/contractions/tree/master) library for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Expand contractions in the text using the `contractions` library.\n",
    "\n",
    "    :param text: Input text\n",
    "    :return: Text with contractions expanded\n",
    "    \"\"\"\n",
    "\n",
    "    expanded_words = [contractions.fix(word) for word in text.split()]\n",
    "    expanded_text = \" \".join(expanded_words)  # type: ignore\n",
    "    return expanded_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "\n",
    "The text is tokenized into words. This also removes punctuation and any special characters.\n",
    "\n",
    "The [`RegexpTokenizer`](https://www.nltk.org/api/nltk.tokenize.RegexpTokenizer.html) tokenizer is used for tokenization by aplphanumeric words and to ignore all other characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Tokenize the input text using NLTK's RegexpTokenizer.\n",
    "\n",
    "    :param text: Input text\n",
    "    :return: List of tokens\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "\n",
    "The words are lemmatized to their root form. This is done using the [`WordNetLemmatizer`](https://www.nltk.org/api/nltk.stem.html#nltk.stem.wordnet.WordNetLemmatizer) from the NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "nltk.download(\"wordnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def nltkToWordnet(nltk_tag: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert NLTK POS tags to WordNet POS tags.\n",
    "\n",
    "    :param nltk_tag: NLTK POS tag\n",
    "    :return: WordNet POS tag\n",
    "    \"\"\"\n",
    "\n",
    "    if nltk_tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith(\"N\"):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None  # type: ignore\n",
    "\n",
    "\n",
    "def lemmatize_text(tokens: list) -> list:\n",
    "    \"\"\"\n",
    "    Lemmatize the tokens using NLTK's WordNetLemmatizer.\n",
    "\n",
    "    :param tokens: List of tokens\n",
    "    :return: List of lemmatized words\n",
    "    \"\"\"\n",
    "\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    res_words = []\n",
    "    for word, tag in pos_tags:\n",
    "        tag = nltkToWordnet(tag)\n",
    "        if tag is None:\n",
    "            res_words.append(word)\n",
    "        else:\n",
    "            res_words.append(lemmatizer.lemmatize(word, tag))\n",
    "    return res_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopword Removal\n",
    "\n",
    "Stopwords are removed from the text. Stopwords are common words that do not add much meaning to the text. The [`stopwords`](https://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.wordlist.WordListCorpusReader) from the NLTK library are used for this purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"words\")\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishWords = set(nltk.corpus.words.words())\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens: list) -> str:\n",
    "    \"\"\"\n",
    "    Remove stop words from the list of tokens.\n",
    "\n",
    "    :param tokens: List of tokens\n",
    "    :return: List of tokens without stop words\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_words = [w for w in tokens if (w in englishWords and w not in stop_words)]\n",
    "    filtered_text = \" \".join(filtered_words)\n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Text Cleaning\n",
    "\n",
    "Function to perform text cleaning on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean the input text by applying various preprocessing steps.\n",
    "\n",
    "    :param text: Input text\n",
    "    :return: Cleaned text\n",
    "    \"\"\"\n",
    "    text = lowercase_and_remove_urls(text)\n",
    "    text = expand_contractions(text)\n",
    "    tokens = tokenize_text(text)\n",
    "    tokens = lemmatize_text(tokens)\n",
    "    text = remove_stopwords(tokens)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = widgets.IntProgress(\n",
    "    value=0, min=0, max=len(train_df), description=\"Cleaning:\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(progress)\n",
    "\n",
    "cleaned_data = []\n",
    "train_df = merge_title_and_text(train_df)\n",
    "train_df = handle_missing_data(train_df)\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    content = row[\"content\"] if pd.notnull(row[\"content\"]) else \"\"\n",
    "\n",
    "    cleaned_content = clean_text(content)\n",
    "\n",
    "    cleaned_data.append({\"content\": cleaned_content, \"label\": row[\"label\"]})\n",
    "\n",
    "    progress.value += 1\n",
    "\n",
    "cleaned_train_df = pd.DataFrame(cleaned_data)\n",
    "cleaned_train_df = handle_missing_data(cleaned_train_df)\n",
    "\n",
    "cleaned_train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🥀 Data Augmntation\n",
    "\n",
    "Data augmentation is a technique used to increase the size of the dataset by adding slightly modified copies of the data. This is done to improve the performance of the model by providing more data for training.\n",
    "\n",
    "Jason Wei, Kai Zou, \"EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks\"\n",
    "[Available here](https://arxiv.org/abs/1901.11196)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synonym Replacement\n",
    "\n",
    "In this technique, we replace n words in the sentence with synonyms from WordNet. We choose a random n words from the sentence that are not stop words. We then replace each of these words with a random synonym that is also present in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word: str) -> list:\n",
    "    \"\"\"\n",
    "    Get synonyms for a given word using WordNet.\n",
    "\n",
    "    :param word: Input word\n",
    "    :return: List of synonyms\n",
    "    \"\"\"\n",
    "\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():  # type: ignore\n",
    "            synonyms.add(lemma.name())\n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    return list(synonyms)\n",
    "\n",
    "\n",
    "def synonym_replacement(text: str, n: int) -> str:\n",
    "    \"\"\"\n",
    "    Randomly replace words in the text with their synonyms.\n",
    "\n",
    "    :param text: Input text\n",
    "    :param n: Number of words to replace\n",
    "    :return: Text with words replaced by synonyms\n",
    "    \"\"\"\n",
    "\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if wordnet.synsets(word)]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(synonyms)\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "\n",
    "    sentence = \" \".join(new_words)\n",
    "\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Insertion\n",
    "\n",
    "In random insertion, we randomly insert synonyms of a word into the sentence n times. This is done by first finding a synonym of a word and then inserting it into the sentence at a random position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_word(word: str, sentence: str) -> str:\n",
    "    \"\"\"\n",
    "    Add a word at a random position in the sentence.\n",
    "\n",
    "    :param word: Word to add\n",
    "    :param sentence: Original sentence\n",
    "    :return: Sentence with the word added\n",
    "    \"\"\"\n",
    "\n",
    "    words = sentence.split()\n",
    "    random_idx = random.randint(0, len(words) - 1)\n",
    "    words.insert(random_idx, word)\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def random_insertion(text: str, n: int) -> str:\n",
    "    \"\"\"\n",
    "    Randomly insert words into the text.\n",
    "\n",
    "    :param text: Input text\n",
    "    :param n: Number of words to insert\n",
    "    :return: Text with words inserted\n",
    "    \"\"\"\n",
    "\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        random_word = random.choice(words)\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if synonyms:\n",
    "            synonym = random.choice(synonyms)\n",
    "            new_words = add_word(synonym, \" \".join(new_words)).split()\n",
    "\n",
    "    return \" \".join(new_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Swap\n",
    "\n",
    "In random swap, we randomly swap two words in the sentence n times. This is done by randomly choosing two words in the sentence and then swapping their positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_swap(text: str, n: int) -> str:\n",
    "    \"\"\"\n",
    "    Randomly swap words in the text.\n",
    "\n",
    "    :param text: Input text\n",
    "    :param n: Number of words to swap\n",
    "    :return: Text with words swapped\n",
    "    \"\"\"\n",
    "\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        idx1, idx2 = random.sample(range(len(words)), 2)\n",
    "        new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n",
    "\n",
    "    return \" \".join(new_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Deletion\n",
    "\n",
    "In random deletion, we randomly delete each word in the sentence with a probability p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_deletion(text: str, p: float) -> str:\n",
    "    \"\"\"\n",
    "    Randomly delete words from the text with a given probability.\n",
    "\n",
    "    :param text: Input text\n",
    "    :param p: Probability of deletion\n",
    "    :return: Text with words deleted\n",
    "    \"\"\"\n",
    "\n",
    "    words = text.split()\n",
    "    if len(words) == 1:\n",
    "        return text\n",
    "\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > p:\n",
    "            new_words.append(word)\n",
    "\n",
    "    if len(new_words) == 0:\n",
    "        return random.choice(words)\n",
    "\n",
    "    return \" \".join(new_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Data Augmentation\n",
    "\n",
    "Function to perform text augmentation on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonymReplaced_data = []\n",
    "randomInserted_data = []\n",
    "randomSwapped_data = []\n",
    "randomDeleted_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = widgets.IntProgress(\n",
    "    value=0, min=0, max=len(cleaned_train_df), description=\"Augmenting:\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(progress)\n",
    "\n",
    "for index, row in cleaned_train_df.iterrows():\n",
    "    content = row[\"content\"] if pd.notnull(row[\"content\"]) else row[\"content\"]\n",
    "\n",
    "    try:\n",
    "        if pd.notnull(content):\n",
    "            try:\n",
    "                synonymReplaced_content = synonym_replacement(\n",
    "                    content, (len(content.split()) // 3)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Synonym replacement error for content: {e}\")\n",
    "                synonymReplaced_content = content\n",
    "\n",
    "            try:\n",
    "                randomInserted_content = random_insertion(\n",
    "                    content, (len(content.split()) // 3)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Random insertion error for content: {e}\")\n",
    "                randomInserted_content = content\n",
    "\n",
    "            try:\n",
    "                randomSwapped_content = random_swap(\n",
    "                    content, (len(content.split()) // 3)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Random swap error for content: {e}\")\n",
    "                randomSwapped_content = content\n",
    "\n",
    "            try:\n",
    "                randomDeleted_content = random_deletion(content, 0.1)\n",
    "            except Exception as e:\n",
    "                print(f\"Random deletion error for content: {e}\")\n",
    "                randomDeleted_content = content\n",
    "        else:\n",
    "            synonymReplaced_content = content\n",
    "            randomInserted_content = content\n",
    "            randomSwapped_content = content\n",
    "            randomDeleted_content = content\n",
    "    except Exception as e:\n",
    "        print(f\"Augmentation error for content: {e}\")\n",
    "        synonymReplaced_content = content\n",
    "        randomInserted_content = content\n",
    "        randomSwapped_content = content\n",
    "        randomDeleted_content = content\n",
    "\n",
    "    synonymReplaced_data.append(\n",
    "        {\n",
    "            \"content\": synonymReplaced_content,\n",
    "            \"label\": row[\"label\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    randomInserted_data.append(\n",
    "        {\n",
    "            \"content\": randomInserted_content,\n",
    "            \"label\": row[\"label\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    randomSwapped_data.append(\n",
    "        {\n",
    "            \"content\": randomSwapped_content,\n",
    "            \"label\": row[\"label\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    randomDeleted_data.append(\n",
    "        {\n",
    "            \"content\": randomDeleted_content,\n",
    "            \"label\": row[\"label\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    progress.value += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonymReplaced_df = pd.DataFrame(synonymReplaced_data)\n",
    "randomInserted_df = pd.DataFrame(randomInserted_data)\n",
    "randomSwapped_df = pd.DataFrame(randomSwapped_data)\n",
    "randomDeleted_df = pd.DataFrame(randomDeleted_data)\n",
    "\n",
    "augmented_df = pd.concat(\n",
    "    [synonymReplaced_df, randomInserted_df, randomSwapped_df, randomDeleted_df]\n",
    ")\n",
    "\n",
    "final_train_df = (\n",
    "    pd.concat([cleaned_train_df, augmented_df]).sample(frac=1).reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final training set size: {final_train_df.shape}\")\n",
    "final_train_df.to_csv(\"dataset_and_corpora/augmented_train.csv\")\n",
    "final_train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎭 Sentiment Analysis\n",
    "\n",
    "TextBlob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text: str) -> TextBlob.sentiment:  # type: ignore\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of the given text using TextBlob.\n",
    "\n",
    "    :param text: Input text\n",
    "    :return: Sentiment analysis result\n",
    "    \"\"\"\n",
    "\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add sentiment analysis results (polarity and subjectivity) to the DataFrame.\n",
    "\n",
    "    :param df: DataFrame to process\n",
    "    :return: DataFrame with sentiment analysis results\n",
    "    \"\"\"\n",
    "\n",
    "    progress = widgets.IntProgress(\n",
    "        value=0, min=0, max=len(df), description=\"Sentiment Analysis:\"\n",
    "    )\n",
    "    display(progress)\n",
    "\n",
    "    polarity = []\n",
    "    subjectivity = []\n",
    "\n",
    "    for _index, row in df.iterrows():\n",
    "        sentiment = analyze_sentiment(row[\"content\"])\n",
    "        polarity.append(sentiment.polarity)\n",
    "        subjectivity.append(sentiment.subjectivity)\n",
    "        progress.value += 1\n",
    "\n",
    "    df[\"polarity\"] = polarity\n",
    "    df[\"subjectivity\"] = subjectivity\n",
    "    df = df[[\"content\", \"polarity\", \"subjectivity\", \"label\"]]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df = add_sentiment(final_train_df)\n",
    "final_train_df.to_csv(\"dataset_and_corpora/augmented_train_senti.csv\", index=False)\n",
    "final_train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔢 Feature Extraction\n",
    "\n",
    "<!-- TODO: Explain -->\n",
    "\n",
    "| Model               | Best Feature Extraction Method |\n",
    "| :------------------ | :----------------------------- |\n",
    "| Random Forest       | TF-IDF + Chi-Square            |\n",
    "| Logistic Regression | TF-IDF + Information Gain      |\n",
    "| Gradient Boosting   | GloVe + PCA                    |\n",
    "<!-- | SVM                 | TF-IDF + BoW                   |\n",
    "| DistilBERT          | Fine-tuned BERT embeddings     | -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df = pd.read_csv(\"dataset_and_corpora/augmented_train_senti.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vectorizer(model, filename, folder=\"vectorizers\"):\n",
    "    \"\"\"Save a model or object to the specified folder.\"\"\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"[INFO] Saved model to {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Feature Extarction\n",
    "\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) is a statistical measure used in natural language processing and information retrieval to evaluate the importance of a word in a document relative to a collection of documents (corpus).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tfidf_features(df: pd.DataFrame, max_features: int = 5000) -> csr_matrix:\n",
    "    \"\"\"\n",
    "    Extract TF-IDF features from the 'content' column of the DataFrame.\n",
    "\n",
    "    :param df: Input DataFrame with a 'content' column\n",
    "    :param max_features: Maximum number of features to extract\n",
    "    :return: TF-IDF features as a sparse matrix\n",
    "    \"\"\"\n",
    "\n",
    "    progress = widgets.IntProgress(value=0, min=0, max=1, description=\"TF-IDF:\")\n",
    "    display(progress)\n",
    "\n",
    "    df[\"content\"] = df[\"content\"].fillna(\"\")\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    tfidf_features = csr_matrix(vectorizer.fit_transform(df[\"content\"]))\n",
    "    save_vectorizer(vectorizer, \"final_tfidf_vectorizer.pkl\")\n",
    "\n",
    "    progress.value = 1\n",
    "    return tfidf_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chi-Square Feature Extraction\n",
    "\n",
    "=yes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chi2_features(\n",
    "    tfidf_features: csr_matrix, labels: np.ndarray, k: int = 5000\n",
    ") -> csr_matrix:\n",
    "    \"\"\"\n",
    "    Extract top k features using the Chi-Square test.\n",
    "\n",
    "    :param tfidf_features: TF-IDF features as a sparse matrix\n",
    "    :param labels: Labels corresponding to the features\n",
    "    :param k: Number of top features to select\n",
    "    :return: Reduced feature set as a sparse matrix\n",
    "    \"\"\"\n",
    "    progress = widgets.IntProgress(value=0, min=0, max=1, description=\"Chi2:\")\n",
    "    display(progress)\n",
    "\n",
    "    chi2_selector = SelectKBest(chi2, k=k)\n",
    "    chi2_features = csr_matrix(chi2_selector.fit_transform(tfidf_features, labels))\n",
    "\n",
    "    save_vectorizer(chi2_selector, \"final_chi2_selector.pkl\")\n",
    "    progress.value = 1\n",
    "    return chi2_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words Feature Extraction\n",
    "\n",
    "=yes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bow_features(tfidf_vectorizer: TfidfVectorizer, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Extract Bag of Words (BoW) features based on the vocabulary of a fitted TF-IDF vectorizer.\n",
    "    \"\"\"\n",
    "\n",
    "    progress = widgets.IntProgress(value=0, min=0, max=1, description=\"BoW:\")\n",
    "    display(progress)\n",
    "\n",
    "    df[\"content\"] = df[\"content\"].fillna(\"\")\n",
    "\n",
    "    bow_vectorizer = CountVectorizer(vocabulary=tfidf_vectorizer.vocabulary_)\n",
    "\n",
    "    bow_features = bow_vectorizer.fit_transform(df[\"content\"])\n",
    "\n",
    "    save_vectorizer(bow_vectorizer, \"final_bow_vectorizer.pkl\")\n",
    "\n",
    "    progress.value = 1\n",
    "    return bow_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information Gain Feature Extraction\n",
    "\n",
    "=yes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information_gain_features(\n",
    "    tfidf_features: csr_matrix, labels: np.ndarray, k: int = 5000\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract top k features using Information Gain (Mutual Information)\n",
    "    and return (reduced features as array, fitted SelectKBest object).\n",
    "    \"\"\"\n",
    "    progress = widgets.IntProgress(value=0, min=0, max=1, description=\"InfoGain:\")\n",
    "    display(progress)\n",
    "\n",
    "    labels = labels.astype(int)\n",
    "\n",
    "    infogain_selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "    reduced_features = infogain_selector.fit_transform(tfidf_features, labels)\n",
    "\n",
    "    save_vectorizer(infogain_selector, \"final_infogain_selector.pkl\")\n",
    "\n",
    "    progress.value = 1\n",
    "    return reduced_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Feature Extraction\n",
    "\n",
    "GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\n",
    "\n",
    "**Introduced in** Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf).\n",
    "\n",
    "Before running the cell, please download and move the pre-trained word vectors (Wikipedia 2014 + Gigaword 5) from [here](https://nlp.stanford.edu/data/glove.6B.zip) to the `datasets_and_corpora` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glove_features(\n",
    "    df: pd.DataFrame,\n",
    "    glove_path: str = \"dataset_and_corpora/glove.6B.100d.txt\",\n",
    "    embedding_dim: int = 100,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract GloVe features from the 'content' column of the DataFrame.\n",
    "\n",
    "    :param df: Input DataFrame with a 'content' column\n",
    "    :param glove_path: Path to the GloVe embeddings file\n",
    "    :param embedding_dim: Dimension of the GloVe embeddings\n",
    "    :return: GloVe features as a NumPy array\n",
    "    \"\"\"\n",
    "    progress = widgets.IntProgress(value=0, min=0, max=len(df), description=\"GloVe:\")\n",
    "    display(progress)\n",
    "\n",
    "    # Load GloVe embeddings\n",
    "    glove_embeddings = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype=\"float32\")\n",
    "            glove_embeddings[word] = vector\n",
    "\n",
    "    # Compute sentence embeddings\n",
    "    sentences = [content.split() for content in df[\"content\"]]\n",
    "    glove_features = np.array(\n",
    "        [\n",
    "            np.mean(\n",
    "                [\n",
    "                    glove_embeddings[word]\n",
    "                    for word in sentence\n",
    "                    if word in glove_embeddings\n",
    "                ]\n",
    "                or [np.zeros(embedding_dim, dtype=\"float32\")],\n",
    "                axis=0,\n",
    "            )\n",
    "            for sentence in sentences\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for _ in range(len(df)):\n",
    "        progress.value += 1\n",
    "\n",
    "    return glove_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Feature Extraction\n",
    "\n",
    "=yes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(features: np.ndarray, n_components: int = 100) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform PCA on the given features to reduce dimensionality.\n",
    "\n",
    "    :param features: Input features as a NumPy array\n",
    "    :param n_components: Number of principal components to retain\n",
    "    :return: Reduced features as a NumPy array\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "\n",
    "    save_vectorizer(pca, \"final_pca_model.pkl\")\n",
    "\n",
    "    return reduced_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBERT Feature Extraction\n",
    "\n",
    "[DistilBERT](https://huggingface.co/docs/transformers/en/model_doc/distilbert) is pretrained by knowledge distillation to create a smaller model with faster inference and requires less compute to train. Through a triple loss objective during pretraining, language modeling loss, distillation loss, cosine-distance loss, DistilBERT demonstrates similar performance to a larger transformer language model.\n",
    "\n",
    "**Introduced in** Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TextDataset(Dataset):\n",
    "#     def __init__(self, texts):\n",
    "#         self.texts = texts\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.texts[idx]\n",
    "\n",
    "\n",
    "# def extract_bert_features(\n",
    "#     df: pd.DataFrame,\n",
    "#     model_name: str = \"distilbert-base-uncased\",\n",
    "#     batch_size: int = 3,  # Reduce batch size for memory efficiency\n",
    "#     output_file: str = \"features/distilbert_vectorizer.pkl\",\n",
    "# ) -> str:\n",
    "#     \"\"\"\n",
    "#     Extract BERT features from the 'content' column of the DataFrame.\n",
    "\n",
    "#     :param df: Input DataFrame with a 'content' column\n",
    "#     :param model_name: Name of the pre-trained BERT model\n",
    "#     :param batch_size: Number of samples to process at once\n",
    "#     :param output_file: Path to save the extracted features\n",
    "#     :return: Path to the saved features file\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Load tokenizer and model\n",
    "#     tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "#     model = DistilBertModel.from_pretrained(model_name)\n",
    "#     model.eval()\n",
    "\n",
    "#     # Decide device (CPU or GPU)\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     # model.to(device)\n",
    "\n",
    "#     # Create dataset and dataloader\n",
    "#     dataset = TextDataset(df[\"content\"].tolist())\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     progress = widgets.IntProgress(value=0, min=0, max=len(df), description=\"BERT:\")\n",
    "#     display(progress)\n",
    "\n",
    "#     all_embeddings = []  # Collect all embeddings in memory\n",
    "\n",
    "#     for batch in dataloader:\n",
    "#         inputs = tokenizer(\n",
    "#             batch,\n",
    "#             return_tensors=\"pt\",\n",
    "#             truncation=True,\n",
    "#             padding=True,\n",
    "#             max_length=512,\n",
    "#         )\n",
    "#         inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "#         # Forward pass\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "\n",
    "#         # Extract CLS token embeddings\n",
    "#         cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "#         all_embeddings.append(cls_embeddings)\n",
    "\n",
    "#         progress.value += len(batch)\n",
    "\n",
    "#         # Clear memory\n",
    "#         del inputs, outputs, cls_embeddings\n",
    "#         gc.collect()\n",
    "\n",
    "#     # Save all embeddings to a single pickle file\n",
    "#     with open(output_file, \"wb\") as f:\n",
    "#         pickle.dump(np.vstack(all_embeddings), f)\n",
    "\n",
    "#     print(f\"Features saved to {output_file}\")\n",
    "#     return output_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"features\", exist_ok=True)\n",
    "\n",
    "tfidf_features = extract_tfidf_features(final_train_df)\n",
    "with open(\"features/tfidf_features.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tfidf_features, file)\n",
    "\n",
    "tfidf_chi2_features = extract_chi2_features(\n",
    "    tfidf_features, final_train_df[\"label\"].to_numpy()\n",
    ")\n",
    "with open(\"features/tfidf_chi2_features.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tfidf_chi2_features, file)\n",
    "del tfidf_chi2_features\n",
    "\n",
    "with open(\"vectorizers/final_tfidf_vectorizer.pkl\", \"rb\") as file:\n",
    "    tfidf_vectorizer = pickle.load(file)\n",
    "\n",
    "tfidf_bow_features = extract_bow_features(tfidf_vectorizer, final_train_df)\n",
    "with open(\"features/tfidf_bow_features.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tfidf_bow_features, file)\n",
    "del tfidf_bow_features\n",
    "\n",
    "final_train_df[\"label\"] = final_train_df[\"label\"].astype(int)\n",
    "tfidf_info_gain_features = extract_information_gain_features(\n",
    "    tfidf_features, final_train_df[\"label\"].to_numpy(), k=5000\n",
    ")\n",
    "with open(\"features/tfidf_info_gain_features.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tfidf_info_gain_features, file)\n",
    "del tfidf_info_gain_features\n",
    "\n",
    "del tfidf_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_features = extract_glove_features(final_train_df)\n",
    "with open(\"features/glove_features.pkl\", \"wb\") as file:\n",
    "    pickle.dump(glove_features, file)\n",
    "\n",
    "reduced_glove_features = perform_pca(glove_features)\n",
    "\n",
    "del glove_features\n",
    "\n",
    "with open(\"features/glove_pca_features.pkl\", \"wb\") as file:\n",
    "    pickle.dump(reduced_glove_features, file)\n",
    "\n",
    "del reduced_glove_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📱 Display Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayRandomSample(df: pd.DataFrame, dataType: int) -> None:\n",
    "    \"\"\"\n",
    "    Display a random sample from the DataFrame.\n",
    "\n",
    "    :param df: DataFrame to sample from\n",
    "    :param dataType: Type of DataFrame to sample from (0 for original, 1 for augmented)\n",
    "    \"\"\"\n",
    "\n",
    "    if dataType == 0:\n",
    "        sample = df.sample(n=1)\n",
    "        print(f\"idx: {sample.index[0]}\")\n",
    "        text = sample.iloc[0][\"text\"]\n",
    "        if isinstance(text, str):\n",
    "            text = f\"{text[:200]}...\"\n",
    "        else:\n",
    "            text = \"N/A\"\n",
    "        display(\n",
    "            HTML(\n",
    "                f\"<b>Original:</b><br>\"\n",
    "                f\"<b>Title:</b> {sample.iloc[0]['title']}<br>\"\n",
    "                f\"<b>Text:</b> {text}<br>\"\n",
    "                f\"<b>Label:</b> {sample.iloc[0]['label']}<br>\"\n",
    "            )\n",
    "        )\n",
    "    if dataType == 1:\n",
    "        sample = df.sample(n=1)\n",
    "        print(f\"idx: {sample.index[0]}\")\n",
    "        text = sample.iloc[0][\"content\"]\n",
    "        if isinstance(text, str):\n",
    "            text = f\"{text[:200]}...\"\n",
    "        else:\n",
    "            text = \"N/A\"\n",
    "        display(\n",
    "            HTML(\n",
    "                f\"<b>Augmented:</b><br>\"\n",
    "                f\"<b>Content:</b> {text}<br>\"\n",
    "                f\"<b>Polarity:</b> {sample.iloc[0]['polarity']}<br>\"\n",
    "                f\"<b>Subjectivity:</b> {sample.iloc[0]['subjectivity']}<br>\"\n",
    "                f\"<b>Label:</b> {sample.iloc[0]['label']}\"\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayRandomSample(final_train_df, 1)\n",
    "print(final_train_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 🧠 Model Shenanigans\n",
    "\n",
    "The Ensemble model uses the predictions of 3 different models.\n",
    "\n",
    "These models are trained on the training data that has been cleaned and augmented in the previous sections.\n",
    "More details of the models will be given in their own sub sections.\n",
    "\n",
    "Three models are trained for ensemble learning model:\n",
    "1. [Random Forest (RF)](#random-forest)\n",
    "2. [Logistic Regression (LR)](#logistic-regression)\n",
    "3. [Gradient Boosting (LightGBM)](#gradient-boosting-lightgbm)\n",
    "<!-- 2. Support Vector Machine (SVM) -->\n",
    "<!-- 3. Small BERT (DistilBERT) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌳 Random Forest\n",
    "\n",
    "A Random Forest is a powerful ensemble machine learning algorithm that builds and aggregates the predictions of multiple [decision trees](https://scikit-learn.org/stable/modules/tree.html) to improve accuracy, robustness, and generalization. It is especially effective for classification tasks such as fake news detection, where complex patterns and high-dimensional feature spaces are common. In this implementation, we use scikit-learn’s [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) with `n_estimators=100`, meaning the ensemble consists of 100 individual decision trees\n",
    "\n",
    "The following code performs:\n",
    "1. _[Feature Loading](#loading-tf-idf--chi-square-features):_ Loading the preprocessed features ([TF-IDF vectors selected by Chi-Squared test](#chi-square-feature-extraction))\n",
    "2. _[K-Fold Cross-Validation](#test-rf-with-k-fold-cross-validation):_ Uses 5-fold cross-validation to evaluate the models performance.\n",
    "3. _Ensemble Predictions:_ Store the predictions (in [`predictions/rf_ensemble_predictions.pkl`](predictions/rf_ensemble_predictions.pkl)) of all folds to enable the ensemble analysis.\n",
    "4. _[Final Model](#train-rf-on-training-set):_ A final Random Forest model is trained on the entire testing set and saves the final trained model (in [`models/rf_model.pkl`](models/rf_model.pkl)) for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading TF-IDF + Chi-Square Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features/tfidf_chi2_features.pkl\", \"rb\") as file:\n",
    "    tfidf_chi2_features = pickle.load(file)\n",
    "\n",
    "if isinstance(tfidf_chi2_features, csr_matrix):\n",
    "    tfidf_chi2_features = tfidf_chi2_features.toarray()\n",
    "\n",
    "labels = final_train_df[\"label\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test RF with K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "ensemble_predictions = np.zeros((tfidf_chi2_features.shape[0], len(np.unique(labels))))\n",
    "\n",
    "rf_model = None\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(tfidf_chi2_features)):\n",
    "    print(f\"Fold {fold + 1}/{k}\")\n",
    "\n",
    "    X_train, X_test = tfidf_chi2_features[train_idx], tfidf_chi2_features[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_pred_proba = rf_model.predict_proba(X_test)\n",
    "\n",
    "    ensemble_predictions[test_idx] = y_pred_proba\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    fold_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nAverage Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
    "\n",
    "with open(\"predictions/rf_ensemble_predictions.pkl\", \"wb\") as file:\n",
    "    pickle.dump(ensemble_predictions, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RF on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "final_rf_model.fit(tfidf_chi2_features, labels)\n",
    "\n",
    "# Save the final trained model\n",
    "with open(\"models/rf_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(final_rf_model, file)\n",
    "\n",
    "print(\"Final Random Forest model trained on the full dataset and saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "yes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Features and Converting to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "# from sklearn.metrics import (\n",
    "#     classification_report,\n",
    "#     confusion_matrix,\n",
    "#     accuracy_score,\n",
    "#     f1_score,\n",
    "# )\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from scipy.sparse import csr_matrix\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Load features and labels\n",
    "# with open(\"features/tfidf_bow_features.pkl\", \"rb\") as file:\n",
    "#     tfidf_bow_features = pickle.load(file)\n",
    "\n",
    "# labels = final_train_df[\"label\"].to_numpy()\n",
    "\n",
    "# # Downcast features to reduce memory usage\n",
    "# if isinstance(tfidf_bow_features, csr_matrix):\n",
    "#     tfidf_bow_features.data = tfidf_bow_features.data.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training using K-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define pipeline (scaling + SVM)\n",
    "# pipeline = Pipeline(\n",
    "#     [\n",
    "#         # (\"scaler\", StandardScaler(with_mean=False)),  # Avoid centering sparse data\n",
    "#         (\"svm\", SVC(probability=True, class_weight=\"balanced\")),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Define parameter grid for GridSearch\n",
    "# param_grid = {\n",
    "#     \"svm__kernel\": [\"linear\", \"rbf\"],\n",
    "#     \"svm__C\": [0.1, 1, 10],\n",
    "#     \"svm__gamma\": [\"scale\", \"auto\"],\n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=pipeline,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring=\"f1\",\n",
    "#     cv=cv,  # Reduce folds to minimize memory/time cost\n",
    "#     verbose=1,\n",
    "#     n_jobs=4,\n",
    "#     error_score=\"raise\",\n",
    "# )\n",
    "\n",
    "# # Run Grid Search\n",
    "# grid_search.fit(tfidf_bow_features, labels)\n",
    "\n",
    "# # Print best parameters and score\n",
    "# print(\"\\nBest Parameters:\")\n",
    "# print(grid_search.best_params_)\n",
    "# print(\"\\nBest F1 Score: {:.4f}\".format(grid_search.best_score_))\n",
    "\n",
    "# # Save best model\n",
    "# with open(\"models/best_svm_model_gridsearch.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(grid_search.best_estimator_, file)\n",
    "\n",
    "# print(\"[SVM] Best model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM on Full Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate best model on the full dataset\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred = best_model.predict(tfidf_bow_features)\n",
    "# y_pred_proba = best_model.predict_proba(tfidf_bow_features)[:, 1]\n",
    "\n",
    "# accuracy = accuracy_score(labels, y_pred)\n",
    "# f1 = f1_score(labels, y_pred)\n",
    "# print(\"\\nFinal Accuracy: {:.4f}\".format(accuracy))\n",
    "# print(\"Final F1 Score: {:.4f}\".format(f1))\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(labels, y_pred))\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix(labels, y_pred))\n",
    "\n",
    "# # Cross-validation accuracy\n",
    "# cv_scores = cross_val_score(\n",
    "#     best_model, tfidf_bow_features, labels, cv=3, scoring=\"accuracy\", n_jobs=-1\n",
    "# )\n",
    "# print(\"\\nCross-Validation Accuracy Scores:\", cv_scores)\n",
    "# print(\"Mean CV Accuracy: {:.4f}\".format(cv_scores.mean()))\n",
    "\n",
    "# # Plot cross-validation results\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.lineplot(x=range(1, len(cv_scores) + 1), y=cv_scores, marker=\"o\")\n",
    "# plt.title(\"SVM Cross-Validation Accuracy per Fold\")\n",
    "# plt.xlabel(\"Fold\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.grid(True)\n",
    "# plt.savefig(\"assets/svm_cv_accuracy.png\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📉 Logistic Regression\n",
    "\n",
    "Logistic Regression is a fundamental linear machine learning algorithm widely used for binary and multiclass classification tasks. It models the probability that a given input belongs to a particular class by applying the logistic (sigmoid) function to a linear combination of input features. Logistic Regression is especially valued for its simplicity, interpretability, and efficiency, making it a strong baseline for text classification problems such as fake news detection. In this implementation, a custom logistic regression model is built using PyTorch’s neural network modules, allowing for GPU acceleration and flexible training routines.\n",
    "\n",
    "The following code performs:\n",
    "1. _[Feature Loading](#loading-tf-idf--information-gain-features-and-converting-to-pytorch-tensors):_ Loads the preprocessed features ([TF-IDF vectors selected by Information Gain feature selection](#information-gain-feature-extraction)), converting them into PyTorch tensors for model training.\n",
    "2. _[K-Fold Cross-Validation](#test-lr-with-k-fold-cross-validation):_ Uses 5-fold cross-validation to rigorously evaluate the model’s performance, ensuring that results are robust and generalizable.\n",
    "3. _Ensemble Predictions:_ Stores the probabilistic predictions (in [`predictions/lr_ensemble_predictions.pkl`](predictions/lr_ensemble_predictions.pkl)) from all folds, enabling ensemble analysis and comprehensive performance assessment.\n",
    "4. _[Final Model](#train-lr-on-training-set):_ Trains a final Logistic Regression model on the entire dataset with early stopping based on training loss, and saves the best-performing model (in [`models/lr_model.pth`](models/lr_model.pth)) for future inference or deployment. The training loss per epoch is also saved and visualized for further analysis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading TF-IDF + Information Gain Features and Converting to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features/tfidf_info_gain_features.pkl\", \"rb\") as file:\n",
    "    tfidf_info_gain_features = pickle.load(file)\n",
    "\n",
    "labels = final_train_df[\"label\"].to_numpy()\n",
    "\n",
    "t_tfidf_info_gain_features = torch.tensor(\n",
    "    tfidf_info_gain_features.todense(), dtype=torch.float32\n",
    ")\n",
    "t_labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LR_Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LR with K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "ensemble_predictions = torch.zeros((len(labels), 2), dtype=torch.float32, device=device)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(tfidf_info_gain_features)):\n",
    "    print(f\"\\nFold {fold + 1}/{k}\")\n",
    "\n",
    "    X_train, X_test = (\n",
    "        t_tfidf_info_gain_features[train_idx],\n",
    "        t_tfidf_info_gain_features[test_idx],\n",
    "    )\n",
    "    y_train, y_test = t_labels[train_idx], t_labels[test_idx]\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    lr_model = LR_Model(input_dim=X_train.shape[1]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(lr_model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        lr_model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = lr_model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss:.4f}\")\n",
    "\n",
    "    # Save model for this fold\n",
    "    torch.save(\n",
    "        lr_model.state_dict(),\n",
    "        f\"models/lr_epochs/logistic_regression_fold{fold + 1}.pth\",\n",
    "    )\n",
    "\n",
    "    lr_model.eval()\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = lr_model(batch_X)\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(batch_y)\n",
    "\n",
    "    outputs = torch.cat(all_outputs)\n",
    "    y_test = torch.cat(all_targets)\n",
    "\n",
    "    _, y_pred = torch.max(outputs, 1)\n",
    "    y_pred_proba = torch.softmax(outputs, dim=1)\n",
    "\n",
    "    ensemble_predictions[test_idx] = y_pred_proba\n",
    "\n",
    "    accuracy = accuracy_score(y_test.cpu(), y_pred.cpu())\n",
    "    fold_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test.cpu(), y_pred.cpu()))\n",
    "\n",
    "# Save ensemble predictions\n",
    "with open(\"predictions/lr_ensemble_predictions.pkl\", \"wb\") as file:\n",
    "    pickle.dump(ensemble_predictions.cpu().numpy(), file)\n",
    "\n",
    "# Print average accuracy\n",
    "average_accuracy = sum(fold_accuracies) / k\n",
    "print(f\"\\nAverage Accuracy across {k} folds: {average_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LR on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining final model on full dataset with early stopping...\")\n",
    "\n",
    "full_train_dataset = TensorDataset(t_tfidf_info_gain_features, t_labels)\n",
    "full_train_loader = DataLoader(full_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "final_lr_model = LR_Model(input_dim=tfidf_info_gain_features.shape[1]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(final_lr_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 5\n",
    "best_loss = float(\"inf\")\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    final_lr_model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in full_train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_lr_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(full_train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_loss < best_loss - 1e-4:\n",
    "        best_loss = avg_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(\n",
    "            final_lr_model,\n",
    "            \"models/lr_model.pth\",\n",
    "        )\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
    "        break\n",
    "\n",
    "\n",
    "# Save the loss per epoch data\n",
    "with open(\"assets/lr_training_loss_per_epoch.pkl\", \"wb\") as file:\n",
    "    pickle.dump(train_losses, file)\n",
    "\n",
    "print(\"\\nTraining complete. Best model saved.\")\n",
    "\n",
    "# Now plot the losses\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, marker=\"o\")\n",
    "plt.title(\"Training Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, max(train_losses) * 1.1)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"evaluations/lr_training_loss.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smallbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize k-fold cross-validation\n",
    "# k = 5\n",
    "# kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# # Initialize variables to store results\n",
    "# fold_accuracies = []\n",
    "# ensemble_predictions = torch.zeros((len(labels), 2), dtype=torch.float32)\n",
    "\n",
    "# # Perform k-fold cross-validation\n",
    "# for fold, (train_idx, test_idx) in enumerate(\n",
    "#     kf.split(tfidf_info_gain_features.numpy())\n",
    "# ):\n",
    "#     print(f\"Fold {fold + 1}/{k}\")\n",
    "\n",
    "#     # Split the data into training and testing sets for this fold\n",
    "#     X_train, X_test = (\n",
    "#         tfidf_info_gain_features[train_idx],\n",
    "#         tfidf_info_gain_features[test_idx],\n",
    "#     )\n",
    "#     y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "#     # Create DataLoaders for batch processing\n",
    "#     train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "#     test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#     # Initialize the tokenizer\n",
    "#     tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "#     # Train the model\n",
    "#     num_epochs = 3\n",
    "#     gradient_accumulation_steps = 2\n",
    "#     model.train()\n",
    "#     for epoch in range(num_epochs):\n",
    "#         epoch_loss = 0\n",
    "#         optimizer.zero_grad()\n",
    "#         for step, (batch_X, batch_y) in enumerate(train_loader):\n",
    "#             # Tokenize the input and move to the GPU\n",
    "#             batch_X = tokenizer(\n",
    "#                 batch_X.tolist(), padding=True, truncation=True, return_tensors=\"pt\"\n",
    "#             )\n",
    "#             input_ids = batch_X[\"input_ids\"].to(device)\n",
    "#             attention_mask = batch_X[\"attention_mask\"].to(device)\n",
    "#             batch_y = batch_y.to(device)\n",
    "\n",
    "#             # Forward pass\n",
    "#             outputs = model(\n",
    "#                 input_ids=input_ids, attention_mask=attention_mask, labels=batch_y\n",
    "#             )\n",
    "#             loss = outputs.loss / gradient_accumulation_steps\n",
    "#             loss.backward()\n",
    "#             epoch_loss += loss.item()\n",
    "\n",
    "#             if (step + 1) % gradient_accumulation_steps == 0:\n",
    "#                 optimizer.step()\n",
    "#                 optimizer.zero_grad()\n",
    "\n",
    "#         print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "#     # Evaluate the model\n",
    "#     model.eval()\n",
    "#     all_outputs = []\n",
    "#     all_y_test = []\n",
    "#     with torch.no_grad():\n",
    "#         for batch_X, batch_y in test_loader:\n",
    "#             # Tokenize the input and move to the GPU\n",
    "#             batch_X = tokenizer(\n",
    "#                 batch_X.tolist(), padding=True, truncation=True, return_tensors=\"pt\"\n",
    "#             )\n",
    "#             input_ids = batch_X[\"input_ids\"].to(device)\n",
    "#             attention_mask = batch_X[\"attention_mask\"].to(device)\n",
    "#             batch_y = batch_y.to(device)\n",
    "\n",
    "#             # Forward pass\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             all_outputs.append(outputs.logits)\n",
    "#             all_y_test.append(batch_y)\n",
    "\n",
    "#     # Concatenate outputs and labels\n",
    "#     outputs = torch.cat(all_outputs, dim=0)\n",
    "#     y_test = torch.cat(all_y_test, dim=0)\n",
    "#     _, y_pred = torch.max(outputs, 1)\n",
    "#     y_pred_proba = torch.softmax(outputs, dim=1)\n",
    "\n",
    "#     # Store predictions for ensemble learning\n",
    "#     ensemble_predictions[test_idx] = y_pred_proba\n",
    "\n",
    "#     # Evaluate the model\n",
    "#     accuracy = accuracy_score(y_test.cpu(), y_pred.cpu())\n",
    "#     fold_accuracies.append(accuracy)\n",
    "#     print(f\"Accuracy for fold {fold + 1}: {accuracy:.4f}\")\n",
    "#     print(\n",
    "#         \"\\nClassification Report:\\n\", classification_report(y_test.cpu(), y_pred.cpu())\n",
    "#     )\n",
    "\n",
    "# # Calculate and print the average accuracy across all folds\n",
    "# average_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "# print(f\"\\nAverage Accuracy across {k} folds: {average_accuracy:.4f}\")\n",
    "\n",
    "# # Save the ensemble predictions for later use\n",
    "# with open(\"features/smallbert_ensemble_predictions.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(ensemble_predictions.cpu().numpy(), file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌲 Gradient Boosting (LightGBM)\n",
    "\n",
    "Gradient Boosting is a state-of-the-art ensemble machine learning technique that builds a strong predictive model by combining the outputs of many weak learners, typically decision trees, in a sequential manner. LightGBM (Light Gradient Boosting Machine) is a highly efficient and scalable implementation of gradient boosting, optimized for both speed and performance, and supports GPU acceleration for large-scale data mining tasks. LightGBM is particularly effective for classification problems such as fake news detection, where complex feature interactions and high-dimensional data are common. In this implementation, we use the [LightGBM](https://lightgbm.readthedocs.io/en/latest/) library with GPU support and advanced hyperparameters for robust model training and evaluation.\n",
    "\n",
    "The following code performs:\n",
    "1. _[Feature Loading](#loading-glove--pca-features):_ Loads preprocessed features ([GloVe word embeddings reduced by PCA](#pca-feature-extraction)) to provide dense, informative representations of text data.\n",
    "2. _[K-Fold Cross-Validation](#test-lightgbm-with-k-fold-cross-validation):_ Uses 5-fold cross-validation to rigorously assess model performance, ensuring that results are robust and generalizable across different data splits.\n",
    "3. _Ensemble Predictions:_ Stores probabilistic predictions (in [`predictions/lightgbm_ensemble_predictions.pkl`](predictions/lightgbm_ensemble_predictions.pkl)) from all folds, enabling ensemble analysis and further model comparison.\n",
    "4. _[Final Model](#train-lightgbm-on-training-set):_ Trains a final LightGBM model on the entire dataset, saves the trained model (in [`models/lgbm_model.txt`](models/lgbm_model.txt)), and records the training loss curve for further evaluation and visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading GloVe + PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features/glove_pca_features.pkl\", \"rb\") as file:\n",
    "    glove_pca_features = pickle.load(file)\n",
    "\n",
    "labels = final_train_df[\"label\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LightGBM with K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "ensemble_predictions = np.zeros((len(labels), 2))\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(glove_pca_features)):\n",
    "    print(f\"Fold {fold + 1}/{k}\")\n",
    "\n",
    "    X_train, X_test = glove_pca_features[train_idx], glove_pca_features[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"num_class\": 2,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"device\": \"gpu\",\n",
    "        \"gpu_platform_id\": 0,\n",
    "        \"gpu_device_id\": 0,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"num_leaves\": 31,\n",
    "        \"max_depth\": -1,\n",
    "        \"min_data_in_leaf\": 20,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"verbosity\": -1,\n",
    "        \"early_stopping_rounds\": 100,\n",
    "    }\n",
    "\n",
    "    lgb_model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[train_data, test_data],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50)],\n",
    "    )\n",
    "\n",
    "    if lgb_model is None:\n",
    "        raise ValueError(\n",
    "            \"LightGBM model training failed. Please check the training data and parameters.\"\n",
    "        )\n",
    "\n",
    "    batch_size = 1024\n",
    "\n",
    "    def lazy_predict(X_test, batch_size):\n",
    "        if lgb_model is None:\n",
    "            raise ValueError(\n",
    "                \"LightGBM model is not initialized. Ensure the model is trained before prediction.\"\n",
    "            )\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            batch = X_test[i : i + batch_size]\n",
    "            yield lgb_model.predict(batch, num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "    y_pred_proba = np.vstack(\n",
    "        [np.array(batch) for batch in lazy_predict(X_test, batch_size)]\n",
    "    )\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "    ensemble_predictions[test_idx] = y_pred_proba\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    fold_accuracies.append(accuracy)\n",
    "    print(f\"Accuracy for fold {fold + 1}: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "average_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "print(f\"\\nAverage Accuracy across {k} folds: {average_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "with open(\"predictions/lightgbm_ensemble_predictions.pkl\", \"wb\") as file:\n",
    "    pickle.dump(ensemble_predictions, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LightGBM on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_data = lgb.Dataset(glove_pca_features, label=labels)\n",
    "\n",
    "evals_result = {}\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 2,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"device\": \"gpu\",\n",
    "    \"gpu_platform_id\": 0,\n",
    "    \"gpu_device_id\": 0,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 31,\n",
    "    \"max_depth\": -1,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbosity\": -1,\n",
    "}\n",
    "\n",
    "final_lgb_model = lgb.train(\n",
    "    params,\n",
    "    full_train_data,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[full_train_data],\n",
    "    valid_names=[\"train\"],\n",
    "    callbacks=[\n",
    "        lgb.record_evaluation(evals_result),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Save model\n",
    "final_lgb_model.save_model(\"models/lgbm_model.txt\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(evals_result[\"train\"][\"multi_logloss\"], label=\"Train Loss\")\n",
    "plt.title(\"Final LightGBM Model - Training Loss Curve\")\n",
    "plt.xlabel(\"Boosting Round\")\n",
    "plt.xlim(0, len(evals_result[\"train\"][\"multi_logloss\"]))\n",
    "plt.ylabel(\"Multi Log Loss\")\n",
    "plt.ylim(0, max(evals_result[\"train\"][\"multi_logloss\"]) * 1.1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"evaluations/lgbm_training_loss_curve.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Ensmeble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load base model predictions ===\n",
    "with open(\"predictions/rf_ensemble_predictions.pkl\", \"rb\") as file:\n",
    "    rf_preds = pickle.load(file)\n",
    "with open(\"predictions/lr_ensemble_predictions.pkl\", \"rb\") as file:\n",
    "    lr_preds = pickle.load(file)\n",
    "with open(\"predictions/lightgbm_ensemble_predictions.pkl\", \"rb\") as file:\n",
    "    lgbm_preds = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# base_preds = {\"lgbm\": lgbm_preds, \"lr\": lr_preds, \"rf\": rf_preds, \"svm\": svm_preds}\n",
    "base_preds = {\"lgbm\": lgbm_preds, \"lr\": lr_preds, \"rf\": rf_preds}\n",
    "\n",
    "labels = final_train_df[\"label\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleNet(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(EnsembleNet, self).__init__()\n",
    "        self.stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta-dataset from base predictions\n",
    "X_meta = np.stack(\n",
    "    # [base_preds[\"lgbm\"], base_preds[\"lr\"], base_preds[\"rf\"], base_preds[\"svm\"]], axis=1\n",
    "    [base_preds[\"lgbm\"], base_preds[\"lr\"], base_preds[\"rf\"]],\n",
    "    axis=1,\n",
    ")\n",
    "X_meta = X_meta.reshape(X_meta.shape[0], -1)\n",
    "y_meta = labels\n",
    "\n",
    "# Convert to PyTorch tensors and move to GPU\n",
    "X_tensor = torch.FloatTensor(X_meta).to(device)\n",
    "y_tensor = torch.FloatTensor(y_meta).unsqueeze(1).to(device)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "model = EnsembleNet(input_size=X_meta.shape[1]).to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training settings\n",
    "epochs = 100\n",
    "patience = 10\n",
    "best_f1 = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "train_losses = []\n",
    "train_f1s = []\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(y_meta)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "        acc = accuracy_score(y_meta, preds.cpu().numpy())\n",
    "        f1 = f1_score(y_meta, preds.cpu().numpy())\n",
    "        train_f1s.append(f1)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{epochs} | Loss: {avg_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        torch.save(model.state_dict(), \"models/ensemble_model_best.pth\")\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\n",
    "            f\"Early stopping triggered after {patience} epochs without improvement.\\n\"\n",
    "        )\n",
    "        break\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"models/ensemble_model_best.pth\"))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_tensor)\n",
    "    final_preds = (torch.sigmoid(outputs) > 0.5).float().cpu().numpy()\n",
    "\n",
    "print(\"\\nFinal Evaluation:\")\n",
    "print(classification_report(y_meta, final_preds))\n",
    "print(f\"Ensemble Accuracy: {accuracy_score(y_meta, final_preds):.4f}\")\n",
    "print(f\"Ensemble F1-Score: {f1_score(y_meta, final_preds):.4f}\")\n",
    "\n",
    "# Save full model for deployment\n",
    "torch.save(model, \"models/full_ensemble_model.pth\")\n",
    "print(\"\\nFinal ensemble model saved successfully at 'models/full_ensemble_model.pth'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, marker=\"o\")\n",
    "plt.title(\"Training Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, max(train_losses) * 1.05)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_f1s) + 1), train_f1s, marker=\"o\", color=\"green\")\n",
    "plt.title(\"Training F1 Score per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"assets/ensemble_training_curves.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🗳️ Max Voting Model\n",
    "\n",
    "An Ensemble Model combines the predictive strengths of multiple diverse machine learning algorithms to achieve higher accuracy, stability, and generalization than any single model alone. In fake news detection, ensemble methods are particularly valuable for leveraging the complementary strengths of different classifiers and mitigating individual model weaknesses. This implementation aggregates the outputs of three high-performing models-Random Forest, Logistic Regression, and LightGBM-using both soft (probability averaging) and hard (majority voting) ensemble strategies.\n",
    "\n",
    "The following code performs:\n",
    "1. _[Prediction Loading](#loading-base-model-predictions):_ Loads the probabilistic predictions from the Random Forest, Logistic Regression, and LightGBM models, each trained and validated via cross-validation on the same dataset.\n",
    "2. _[Probability Calibration](#probability-normalization):_ Ensures that all model outputs are in probability format, extracting the probability of the positive class for consistent ensemble computation.\n",
    "3. _[Soft Voting Ensemble](#soft-voting-ensemble):_ Computes the average predicted probability across all three models and classifies an instance as positive if the mean probability exceeds 0.5. This approach leverages the confidence of each model for more nuanced decision-making.\n",
    "4. _[Hard Voting Ensemble](#hard-voting-ensemble):_ Applies majority voting by converting each model’s probabilities to binary class predictions and selecting the class predicted by most models for each instance. This approach emphasizes consensus among models for robust classification.\n",
    "5. _[Performance Evaluation](#ensemble-evaluation):_ The ensemble predictions can be compared to ground-truth labels to assess improvements in accuracy and robustness over single-model approaches.\n",
    "\n",
    "---\n",
    "Answer from Perplexity: pplx.ai/share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions/rf_ensemble_predictions.pkl\", \"rb\") as file:\n",
    "    rf_preds_proba = pickle.load(file)\n",
    "\n",
    "with open(\"predictions/lr_ensemble_predictions.pkl\", \"rb\") as file:\n",
    "    lr_preds_proba = pickle.load(file)\n",
    "\n",
    "with open(\"predictions/lightgbm_ensemble_predictions.pkl\", \"rb\") as file:\n",
    "    lgbm_preds_proba = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/rf_model.pkl\", \"rb\") as file:\n",
    "    rf_model = pickle.load(file)\n",
    "\n",
    "input_dim = rf_preds_proba.shape[1] if len(rf_preds_proba.shape) > 1 else 1\n",
    "lr_model = torch.load(\"models/lr_model.pth\", map_location=\"cuda\", weights_only=False)\n",
    "lr_model.eval()\n",
    "\n",
    "lgbm_model = lgb.Booster(model_file=\"models/lgbm_model.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = final_train_df[\"label\"].to_numpy()\n",
    "\n",
    "\n",
    "def to_proba(pred):\n",
    "    \"\"\"\n",
    "    Convert predictions to probabilities if necessary.\n",
    "\n",
    "    :param pred: Predictions or probabilities\n",
    "    :return: Probabilities\n",
    "    \"\"\"\n",
    "    if isinstance(pred, np.ndarray) and len(pred.shape) == 2 and pred.shape[1] == 2:\n",
    "        return pred[:, 1]\n",
    "    return pred\n",
    "\n",
    "\n",
    "rf_probs = to_proba(rf_preds_proba)\n",
    "lr_probs = to_proba(lr_preds_proba)\n",
    "lgbm_probs = to_proba(lgbm_preds_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_probs = (rf_probs + lr_probs + lgbm_probs) / 3\n",
    "soft_preds = (avg_probs >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classes = (rf_probs >= 0.5).astype(int)\n",
    "lr_classes = (lr_probs >= 0.5).astype(int)\n",
    "lgbm_classes = (lgbm_probs >= 0.5).astype(int)\n",
    "\n",
    "all_class_preds = np.vstack([rf_classes, lr_classes, lgbm_classes])\n",
    "hard_preds, _ = mode(all_class_preds, axis=0)\n",
    "hard_preds = np.squeeze(hard_preds)  # Flatten to match label shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(name: str, preds):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of an ensemble model.\n",
    "\n",
    "    :param name: Name of the ensemble method\n",
    "    :param preds: Predicted labels\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {name} Ensemble ===\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(labels, preds))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(labels, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Evaluations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\"Soft Voting\", soft_preds)\n",
    "evaluate(\"Hard Voting\", hard_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 🍎 Testing Testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Load all pre-fitted vectorizers, selectors, and models needed for test feature extraction.\"\"\"\n",
    "        print(\"[INFO] Loading feature extractors...\")\n",
    "\n",
    "        # Load TF-IDF Vectorizer\n",
    "        with open(\"vectorizers/final_tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "            self.tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "        # Load Chi2 Selector\n",
    "        with open(\"vectorizers/final_chi2_selector.pkl\", \"rb\") as f:\n",
    "            self.chi2_selector = pickle.load(f)\n",
    "\n",
    "        # Load BoW Vectorizer\n",
    "        with open(\"vectorizers/final_bow_vectorizer.pkl\", \"rb\") as f:\n",
    "            self.bow_vectorizer = pickle.load(f)\n",
    "\n",
    "        # Load InfoGain Selector\n",
    "        with open(\"vectorizers/final_infogain_selector.pkl\", \"rb\") as f:\n",
    "            self.infogain_selector = pickle.load(f)\n",
    "\n",
    "        # Load GloVe Embeddings (correct way)\n",
    "        self.glove_embeddings = self.load_glove_embeddings(\n",
    "            \"dataset_and_corpora/glove.6B.100d.txt\"\n",
    "        )\n",
    "\n",
    "        # Load PCA model for GloVe\n",
    "        with open(\"vectorizers/final_pca_model.pkl\", \"rb\") as f:\n",
    "            self.pca_model = pickle.load(f)\n",
    "\n",
    "    def load_glove_embeddings(self, glove_file_path):\n",
    "        \"\"\"Load GloVe embeddings from a text file into a dictionary.\"\"\"\n",
    "        print(\"[INFO] Loading GloVe embeddings...\")\n",
    "        embeddings = {}\n",
    "        with open(glove_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                values = line.strip().split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype=np.float32)\n",
    "                embeddings[word] = vector\n",
    "        print(f\"[INFO] Loaded {len(embeddings)} word vectors from GloVe.\")\n",
    "        return embeddings\n",
    "\n",
    "    def transform_tfidf(self, df):\n",
    "        \"\"\"Transform data using pre-fitted TF-IDF vectorizer.\"\"\"\n",
    "        return self.tfidf_vectorizer.transform(df[\"content\"])\n",
    "\n",
    "    def transform_bow(self, df, max_features=5000):\n",
    "        \"\"\"Transform data using pre-fitted BoW vectorizer.\"\"\"\n",
    "        bow_matrix = self.bow_vectorizer.transform(df[\"content\"])\n",
    "        return bow_matrix.toarray()[:, :max_features]\n",
    "\n",
    "    def transform_chi2(self, tfidf_features):\n",
    "        \"\"\"Transform data using Chi2 selector.\"\"\"\n",
    "        return self.chi2_selector.transform(tfidf_features)\n",
    "\n",
    "    def transform_infogain(self, tfidf_features):\n",
    "        \"\"\"Transform data using InfoGain selector.\"\"\"\n",
    "        return self.infogain_selector.transform(tfidf_features)\n",
    "\n",
    "    def transform_glove(self, df, embedding_dim=100):\n",
    "        \"\"\"Extract GloVe sentence embeddings.\"\"\"\n",
    "        sentences = [content.split() for content in df[\"content\"]]\n",
    "        glove_features = np.array(\n",
    "            [\n",
    "                np.mean(\n",
    "                    [\n",
    "                        self.glove_embeddings.get(word, np.zeros(embedding_dim))\n",
    "                        for word in sentence\n",
    "                    ]\n",
    "                    or [np.zeros(embedding_dim)],\n",
    "                    axis=0,\n",
    "                )\n",
    "                for sentence in sentences\n",
    "            ]\n",
    "        )\n",
    "        return glove_features\n",
    "\n",
    "    def transform_pca_on_glove(self, glove_features):\n",
    "        \"\"\"Reduce GloVe embeddings using pre-fitted PCA.\"\"\"\n",
    "        return self.pca_model.transform(glove_features)\n",
    "\n",
    "    def extract_all_features(self, df):\n",
    "        \"\"\"Main function to transform test data for all models.\"\"\"\n",
    "        tfidf_features = self.transform_tfidf(df)\n",
    "\n",
    "        features = {\n",
    "            \"bow\": self.transform_bow(df),\n",
    "            \"chi2\": self.transform_chi2(tfidf_features),\n",
    "            \"infogain\": self.transform_infogain(tfidf_features),\n",
    "        }\n",
    "\n",
    "        glove_features = self.transform_glove(df)\n",
    "        glove_pca_features = self.transform_pca_on_glove(glove_features)\n",
    "        features[\"glove_pca\"] = glove_pca_features\n",
    "\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"dataset_and_corpora/cleaned_test.csv\")\n",
    "\n",
    "feature_extractor = TestFeatureExtractor()\n",
    "\n",
    "test_labels = pd.read_csv(\"dataset_and_corpora/cleaned_test.csv\")[\"label\"].to_numpy()\n",
    "\n",
    "features = feature_extractor.extract_all_features(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models an Stroing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/rf_model.pkl\", \"rb\") as f:\n",
    "    rf_model = pickle.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class LR_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LR_Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "lr_model = torch.load(\"models/lr_model.pth\", map_location=device, weights_only=False)\n",
    "lr_model.eval()\n",
    "\n",
    "lgb_model = lgb.Booster(model_file=\"models/lgbm_model.txt\")\n",
    "\n",
    "X_chi2 = features[\"chi2\"]\n",
    "X_infogain = features[\"infogain\"]\n",
    "X_glove_pca = features[\"glove_pca\"]\n",
    "y_true = test_df[\"label\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_pred):\n",
    "    \"\"\"Evaluate the performance of a model.\"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n=== {name} Evaluation ===\")\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"Confusion Matrix:\\n\", matrix)\n",
    "\n",
    "    # Save textual metrics\n",
    "    with open(f\"evaluations/{name}_metrics.txt\", \"w\") as f:\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "        f.write(f\"F1 Score: {f1:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(str(report))\n",
    "        f.write(\"\\nConfusion Matrix:\\n\")\n",
    "        f.write(np.array2string(matrix))\n",
    "\n",
    "    print(f\"[INFO] Saved metrics to {name}_metrics.txt\\n\")\n",
    "\n",
    "    # Plot and save confusion matrix with percentages\n",
    "    cm_percent = matrix.astype(\"float\") / matrix.sum(axis=1)[:, np.newaxis] * 100\n",
    "    annot = np.array([[f\"{val:.2f}%\" for val in row] for row in cm_percent])\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    ax = sns.heatmap(\n",
    "        cm_percent,\n",
    "        annot=annot,\n",
    "        fmt=\"\",\n",
    "        cmap=\"Blues\",\n",
    "        cbar=True,\n",
    "        xticklabels=[\"Pred Fake\", \"Pred True\"],\n",
    "        yticklabels=[\"Actual Fake\", \"Actual True\"],\n",
    "    )\n",
    "    ax.xaxis.set_ticks_position(\"top\")\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.title(f\"Confusion Matrix - {name}\", pad=40)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"assets/confusion_matrix_{name}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Random Forest ===\n",
    "y_pred_rf = rf_model.predict(X_chi2)\n",
    "evaluate_model(\"Random Forest\", y_true, y_pred_rf)\n",
    "\n",
    "# === Logistic Regression ===\n",
    "X_infogain_tensor = torch.tensor(X_infogain.todense(), dtype=torch.float32).to(device)\n",
    "lr_probs = lr_model(X_infogain_tensor).detach().cpu().numpy()[:, 1]\n",
    "y_pred_lr = (lr_probs >= 0.5).astype(int)\n",
    "evaluate_model(\"Logistic Regression\", y_true, y_pred_lr)\n",
    "\n",
    "# === LightGBM ===\n",
    "lgbm_probs = lgb_model.predict(X_glove_pca)\n",
    "\n",
    "if issparse(lgbm_probs):\n",
    "    lgbm_probs = lgbm_probs.toarray()  # type: ignore\n",
    "elif isinstance(lgbm_probs, list) and all(issparse(m) for m in lgbm_probs):\n",
    "    lgbm_probs = np.vstack([m.toarray() for m in lgbm_probs])  # type: ignore\n",
    "else:\n",
    "    lgbm_probs = np.asarray(lgbm_probs)\n",
    "\n",
    "# Handle 2D probability arrays (binary classification: [prob_0, prob_1])\n",
    "if lgbm_probs.ndim == 2 and lgbm_probs.shape[1] == 2:\n",
    "    lgbm_probs = lgbm_probs[:, 1]\n",
    "\n",
    "# Threshold to get binary prediction\n",
    "y_pred_lgbm = (lgbm_probs >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model(\"LightGBM\", y_true, y_pred_lgbm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Generating Predictions of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_df[\"label\"].to_numpy()\n",
    "\n",
    "with open(\"models/rf_model.pkl\", \"rb\") as f:\n",
    "    rf_model = pickle.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lr_model = torch.load(\"models/lr_model.pth\", map_location=device, weights_only=False)\n",
    "lr_model.eval()\n",
    "\n",
    "lgb_model = lgb.Booster(model_file=\"models/lgbm_model.txt\")\n",
    "\n",
    "X_chi2 = features[\"chi2\"]\n",
    "X_infogain = features[\"infogain\"]\n",
    "X_glove_pca = features[\"glove_pca\"]\n",
    "\n",
    "rf_test_probs = rf_model.predict_proba(X_chi2)[:, 1]\n",
    "\n",
    "X_infogain_tensor = torch.tensor(X_infogain.toarray(), dtype=torch.float32).to(device)\n",
    "lr_test_probs = lr_model(X_infogain_tensor).detach().cpu().numpy()[:, 1]\n",
    "\n",
    "lgbm_test_probs = lgb_model.predict(X_glove_pca)\n",
    "\n",
    "# Ensure `lgbm_test_probs` is a 1D array by extracting the probabilities for the positive class (class 1)\n",
    "if isinstance(lgbm_test_probs, np.ndarray) and len(lgbm_test_probs.shape) > 1:\n",
    "    lgbm_test_probs = lgbm_test_probs[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_probs = (rf_test_probs + lr_test_probs + lgbm_test_probs) / 3\n",
    "soft_test_preds = (avg_test_probs >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_classes = (np.array(rf_test_probs) >= 0.5).astype(int)\n",
    "lr_test_classes = (np.array(lr_test_probs) >= 0.5).astype(int)\n",
    "lgbm_test_classes = (np.array(lgbm_test_probs) >= 0.5).astype(int)\n",
    "\n",
    "all_test_preds = np.vstack([rf_test_classes, lr_test_classes, lgbm_test_classes])\n",
    "hard_test_preds, _ = mode(all_test_preds, axis=0)\n",
    "hard_test_preds = np.squeeze(hard_test_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(name, preds):\n",
    "    \"\"\"Evaluate the performance of an ensemble model.\"\"\"\n",
    "\n",
    "    print(f\"\\n=== {name} Ensemble Test Evaluation ===\")\n",
    "    acc = accuracy_score(test_labels, preds)\n",
    "    f1 = f1_score(test_labels, preds)\n",
    "    report = classification_report(test_labels, preds)\n",
    "    matrix = confusion_matrix(test_labels, preds)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"Predictions:\\n\", preds)\n",
    "\n",
    "    with open(f\"evaluations/{name}_metrics.txt\", \"w\") as f:\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "        f.write(f\"F1 Score: {f1:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(str(report))\n",
    "        f.write(\"\\nConfusion Matrix:\\n\")\n",
    "        f.write(np.array2string(matrix))\n",
    "\n",
    "    cm_percent = matrix.astype(\"float\") / matrix.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "    annot = np.array([[f\"{val:.2f}%\" for val in row] for row in cm_percent])\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    ax = sns.heatmap(\n",
    "        cm_percent,\n",
    "        annot=annot,\n",
    "        fmt=\"\",\n",
    "        cmap=\"Blues\",\n",
    "        cbar=True,\n",
    "        xticklabels=[\"Pred Fake\", \"Pred True\"],\n",
    "        yticklabels=[\"Actual Fake\", \"Actual True\"],\n",
    "    )\n",
    "    ax.xaxis.set_ticks_position(\"top\")\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.title(f\"Confusion Matrix {name} Ensemble\", pad=40)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"assets/confusion_matrix_{name}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\"Soft Voting\", soft_test_preds)\n",
    "evaluate(\"Hard Voting\", hard_test_preds)\n",
    "\n",
    "with open(\"predictions/soft_voting_test_preds.pkl\", \"wb\") as f:\n",
    "    pickle.dump(soft_test_preds, f)\n",
    "\n",
    "with open(\"predictions/hard_voting_test_preds.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hard_test_preds, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
